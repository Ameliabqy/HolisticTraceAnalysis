{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25f114ee",
   "metadata": {},
   "source": [
    "## CUPTI Counter / FLOPs Analysis\n",
    "\n",
    "### About\n",
    "\n",
    "In this demo we leverage the PyTorch Profiler to capture performance characteristics of CUDA kernels. See the section below on how to collect counters using PyTorch Profiler.\n",
    "\n",
    "### Motivation and context\n",
    "\n",
    "Performance counter measurements can provide insights on how to speed up GPU kernels, conduct roofline analysis and other low level optimizations. The PyTorch Profiler includes a lightweight API to program and measure detailed performance counters from the GPU. This mode leverages [CUPTI Range Profiler API](https://docs.nvidia.com/cupti/r_main.html#r_profiler) and supports an extensive list of performance metrics.\n",
    "\n",
    "The annotated trace contains:\n",
    "* Performance measurement events, which are logged under the `cuda_profiler_range` category.\n",
    "* Counter values, which are logged in the args section of the above events.\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### Collecting the trace with CUPTI Profiler Counters\n",
    "One can collect performance metrics by adding the list of metrics using the experimental config option in PyTorch Profiler.\n",
    "\n",
    "```\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CUDA, torch.profiler.ProfilerActivity.CPU],\n",
    "    record_shapes=True,\n",
    "    on_trace_ready=trace_handler,\n",
    "    experimental_config=torch.profiler._ExperimentalConfig(\n",
    "        profiler_metrics=[\n",
    "            \"kineto__tensor_core_insts\",\n",
    "            \"dram__bytes_read.sum\",\n",
    "            \"dram__bytes_write.sum\"],\n",
    "    profiler_measure_per_kernel=True),\n",
    ") as prof:\n",
    "    res = train_batch(modeldef)\n",
    "    prof.step()```\n",
    "```\n",
    "\n",
    "To collect the trace used in the example we ran [PARAM Benchmarks](https://github.com/facebookresearch/param/tree/main/train/compute/python). PARAM provides a repository of communication and computation micro-benchmarks for AI training and inference. For this example, we ran a simple convolutional neural network model - AlexNet - as a benchmark and collected the trace. Instructions for the same are shown below-\n",
    "\n",
    "Run using the following commands:\n",
    "\n",
    "```\n",
    "# Inside dir \"param/train/compute\"\n",
    "$ python -m python.pytorch.run_benchmark -c python/examples/pytorch/configs/alex_net.json -p -i 1 -d cuda --cupti-profiler --cupti-profiler-measure-per-kernel\n",
    "```\n",
    "\n",
    "#### Trace Analysis\n",
    "\n",
    "To run this demo notebook on your laptop\n",
    "1. Clone the repo `git clone https://github.com/facebookresearch/HolisticTraceAnalysis.git`\n",
    "1. [Optional and recommended] Setup a venv or conda environment. See README for details.\n",
    "1. Set the `trace_dir` parameter in the next cell to the location of the folder containing your collected PyTorch Profiler trace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e32f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hta.trace_analysis import TraceAnalysis\n",
    "from hta.analyzers.cupti_counter_analysis import CUDA_SASS_INSTRUCTION_COUNTER_FLOPS\n",
    "\n",
    "trace_prefix = # ENTER PATH TO HTA HERE\n",
    "trace_dir = f\"{trace_prefix}/tests/data/cupti_profiler/\"\n",
    "analyzer = TraceAnalysis(trace_dir=trace_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf09da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.get_cupti_counter_data_with_operators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49759168",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_kernels = analyzer.get_cupti_counter_data_with_operators(ranks=[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05225cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>op_stack</th>\n",
       "      <th>top_level_op</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_ffma_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_fmul_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_fadd_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_hfma_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_hmul_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_hadd_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_dfma_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_dmul_pred_on.sum</th>\n",
       "      <th>smsp__sass_thread_inst_executed_op_dadd_pred_on.sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>void at::native::(anonymous namespace)::distri...</td>\n",
       "      <td>[cudaLaunchKernel, aten::uniform_, aten::rand]</td>\n",
       "      <td>aten::rand</td>\n",
       "      <td>38731776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4866048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__missing__</td>\n",
       "      <td>[cudaLaunchKernel, cudaFuncSetAttribute, cudaF...</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>9119334400</td>\n",
       "      <td>24780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at...</td>\n",
       "      <td>[cudaLaunchKernel, aten::add_, cudaFuncSetAttr...</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>24780800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49561600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>void at::native::vectorized_elementwise_kernel...</td>\n",
       "      <td>[cudaLaunchKernel, aten::clamp_min_, aten::rel...</td>\n",
       "      <td>aten::relu_</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>void at::native::(anonymous namespace)::max_po...</td>\n",
       "      <td>[cudaLaunchKernel, aten::max_pool2d_with_indic...</td>\n",
       "      <td>aten::max_pool2d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5971968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  void at::native::(anonymous namespace)::distri...   \n",
       "1                                        __missing__   \n",
       "2  void at::native::elementwise_kernel<128, 2, at...   \n",
       "3  void at::native::vectorized_elementwise_kernel...   \n",
       "4  void at::native::(anonymous namespace)::max_po...   \n",
       "\n",
       "                                            op_stack      top_level_op  \\\n",
       "0     [cudaLaunchKernel, aten::uniform_, aten::rand]        aten::rand   \n",
       "1  [cudaLaunchKernel, cudaFuncSetAttribute, cudaF...      aten::conv2d   \n",
       "2  [cudaLaunchKernel, aten::add_, cudaFuncSetAttr...      aten::conv2d   \n",
       "3  [cudaLaunchKernel, aten::clamp_min_, aten::rel...       aten::relu_   \n",
       "4  [cudaLaunchKernel, aten::max_pool2d_with_indic...  aten::max_pool2d   \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_ffma_pred_on.sum  \\\n",
       "0                                           38731776     \n",
       "1                                         9119334400     \n",
       "2                                           24780800     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_fmul_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                           24780800     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_fadd_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_hfma_pred_on.sum  \\\n",
       "0                                            4866048     \n",
       "1                                                  0     \n",
       "2                                           49561600     \n",
       "3                                                  0     \n",
       "4                                            5971968     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_hmul_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_hadd_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_dfma_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_dmul_pred_on.sum  \\\n",
       "0                                                  0     \n",
       "1                                                  0     \n",
       "2                                                  0     \n",
       "3                                                  0     \n",
       "4                                                  0     \n",
       "\n",
       "   smsp__sass_thread_inst_executed_op_dadd_pred_on.sum  \n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "3                                                  0    \n",
       "4                                                  0    "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_kernels.head()[[\"name\", \"op_stack\", \"top_level_op\"]\\\n",
    "                   + list(CUDA_SASS_INSTRUCTION_COUNTER_FLOPS.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5489f0c6-83f0-4a00-9218-f1076b3f6b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_kernels[\"flops\"] = 0\n",
    "for counter, flops in CUDA_SASS_INSTRUCTION_COUNTER_FLOPS.items():\n",
    "    gpu_kernels[\"flops\"] += gpu_kernels[counter] * flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b002062f-72cc-474a-8d10-46dddb217915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>bottom_level_op</th>\n",
       "      <th>top_level_op</th>\n",
       "      <th>flops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>void at::native::(anonymous namespace)::distri...</td>\n",
       "      <td>aten::uniform_</td>\n",
       "      <td>aten::rand</td>\n",
       "      <td>87195648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__missing__</td>\n",
       "      <td>aten::convolution</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>18263449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at...</td>\n",
       "      <td>aten::add_</td>\n",
       "      <td>aten::conv2d</td>\n",
       "      <td>148684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>void at::native::vectorized_elementwise_kernel...</td>\n",
       "      <td>aten::clamp_min_</td>\n",
       "      <td>aten::relu_</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>void at::native::(anonymous namespace)::max_po...</td>\n",
       "      <td>aten::max_pool2d_with_indices</td>\n",
       "      <td>aten::max_pool2d</td>\n",
       "      <td>11943936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  void at::native::(anonymous namespace)::distri...   \n",
       "1                                        __missing__   \n",
       "2  void at::native::elementwise_kernel<128, 2, at...   \n",
       "3  void at::native::vectorized_elementwise_kernel...   \n",
       "4  void at::native::(anonymous namespace)::max_po...   \n",
       "\n",
       "                 bottom_level_op      top_level_op        flops  \n",
       "0                 aten::uniform_        aten::rand     87195648  \n",
       "1              aten::convolution      aten::conv2d  18263449600  \n",
       "2                     aten::add_      aten::conv2d    148684800  \n",
       "3               aten::clamp_min_       aten::relu_            0  \n",
       "4  aten::max_pool2d_with_indices  aten::max_pool2d     11943936  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_kernels[[\"name\", \"bottom_level_op\", \"top_level_op\", \"flops\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b10e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
